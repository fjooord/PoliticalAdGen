{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e20385",
   "metadata": {},
   "source": [
    "# Auto Polling\n",
    "    - This notebook will serve the following pipeline\n",
    "    - Ingest a demographic data, like the census of an area\n",
    "        - Create groups that will in total represent the population\n",
    "            - IE 100/1000 white women ages 20-30\n",
    "        - Turn the groups into personas\n",
    "            - For each group, use chat gpt to make that many personas of people\n",
    "            - Save personas for later use\n",
    "    - Create a survey based on the political landscape of the area\n",
    "        - Feed in the data and make survey\n",
    "        - Could make multiple surveys and have them be specific to the demographic\n",
    "    - Give survey to the personas\n",
    "        - For each persona, have them take the survey, save results\n",
    "    - Process results to determine the most important issues to make ads for\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f276369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.Chat_GPT_Funcs as GPT\n",
    "import concurrent.futures\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f335319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = [\n",
    "#   {\n",
    "#     \"group_size\": 294,\n",
    "#     \"age\": \"18-64\",\n",
    "#     \"gender\": \"Female\",\n",
    "#     \"ethnicity\": \"White\",\n",
    "#     \"income_levels\": \"$20,000 - $50,000\",\n",
    "#     \"employment_status\": \"In civilian labor force (62.9%)\",\n",
    "#     \"marital_status\": \"Not specified\",\n",
    "#     \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "#   },\n",
    "test = [\n",
    "  {\n",
    "    \"group_size\": 146,\n",
    "    \"age\": \"65 and over\",\n",
    "    \"gender\": \"Female\",\n",
    "    \"ethnicity\": \"White\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not in civilian labor force\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 294,\n",
    "    \"age\": \"18-64\",\n",
    "    \"gender\": \"Male\",\n",
    "    \"ethnicity\": \"White\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"In civilian labor force (62.9%)\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 146,\n",
    "    \"age\": \"65 and over\",\n",
    "    \"gender\": \"Male\",\n",
    "    \"ethnicity\": \"White\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not in civilian labor force\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 20,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Black or African American\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 66,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"American Indian and Alaska Native\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 10,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Asian\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 1,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Native Hawaiian and Other Pacific Islander\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 30,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Two or More Races\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 43,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Hispanic or Latino\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89e515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad288ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_persona(i, group_count):\n",
    "    persona_gen_role = GPT.open_file(\"Prompts/persona_gen_groups_v1.txt\")\n",
    "\n",
    "    tags = {\n",
    "        '<<BATCH>>': str(batch_size),\n",
    "        '<<GROUP>>': str(original_dict),\n",
    "        '<<NUM>>': str(i),\n",
    "    }\n",
    "\n",
    "    persona_text = GPT.generalized_gpt_prompt(\"Prompts/gen_by_group.txt\", tags, engine='gpt-4', role=persona_gen_role)\n",
    "    \n",
    "    parent_path = f\"Groups/Group_{group_count}/\"\n",
    "    create_directory_if_not_exists(parent_path)\n",
    "    \n",
    "    file_path = parent_path + f\"group_{group_count}_batch_{i}.txt\"\n",
    "    print(\"Saving:\", file_path)\n",
    "    GPT.save_file(file_path, persona_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e37dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Group: 2\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Starting batch: 9\n",
      "Starting batch: 10\n",
      "Starting batch: 11\n",
      "Starting batch: 12\n",
      "Starting batch: 13\n",
      "Starting batch: 14\n",
      "Starting batch: 15\n",
      "Starting batch: 16\n",
      "Starting batch: 17\n",
      "Starting batch: 18\n",
      "Starting batch: 19\n",
      "Starting batch: 20\n",
      "Starting batch: 21\n",
      "Starting batch: 22\n",
      "Starting batch: 23\n",
      "Starting batch: 24\n",
      "Starting batch: 25\n",
      "Starting batch: 26\n",
      "Starting batch: 27\n",
      "Starting batch: 28\n",
      "Starting batch: 29\n",
      "Saving: Groups/Group_2/group_2_batch_5.txt\n",
      "Saving: Groups/Group_2/group_2_batch_9.txt\n",
      "Saving: Groups/Group_2/group_2_batch_0.txt\n",
      "Saving: Groups/Group_2/group_2_batch_7.txt\n",
      "Saving: Groups/Group_2/group_2_batch_6.txt\n",
      "Saving: Groups/Group_2/group_2_batch_2.txt\n",
      "Saving: Groups/Group_2/group_2_batch_1.txt\n",
      "Saving: Groups/Group_2/group_2_batch_3.txt\n",
      "Saving: Groups/Group_2/group_2_batch_8.txt\n",
      "Saving: Groups/Group_2/group_2_batch_4.txt\n",
      "Saving: Groups/Group_2/group_2_batch_12.txt\n",
      "Saving: Groups/Group_2/group_2_batch_10.txt\n",
      "Saving: Groups/Group_2/group_2_batch_13.txt\n",
      "Saving: Groups/Group_2/group_2_batch_11.txt\n",
      "Saving: Groups/Group_2/group_2_batch_15.txt\n",
      "Saving: Groups/Group_2/group_2_batch_14.txt\n",
      "Saving: Groups/Group_2/group_2_batch_19.txt\n",
      "Saving: Groups/Group_2/group_2_batch_16.txt\n",
      "Saving: Groups/Group_2/group_2_batch_18.txt\n",
      "Saving: Groups/Group_2/group_2_batch_17.txt\n",
      "Saving: Groups/Group_2/group_2_batch_20.txt\n",
      "Saving: Groups/Group_2/group_2_batch_21.txt\n",
      "Saving: Groups/Group_2/group_2_batch_22.txt\n",
      "Saving: Groups/Group_2/group_2_batch_24.txt\n",
      "Saving: Groups/Group_2/group_2_batch_23.txt\n",
      "Saving: Groups/Group_2/group_2_batch_27.txt\n",
      "Saving: Groups/Group_2/group_2_batch_25.txt\n",
      "Saving: Groups/Group_2/group_2_batch_28.txt\n",
      "Saving: Groups/Group_2/group_2_batch_26.txt\n",
      "Saving: Groups/Group_2/group_2_batch_29.txt\n",
      "\n",
      "\n",
      "Starting Group: 3\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Starting batch: 9\n",
      "Starting batch: 10\n",
      "Starting batch: 11\n",
      "Starting batch: 12\n",
      "Starting batch: 13\n",
      "Starting batch: 14\n",
      "Starting batch: 15\n",
      "Starting batch: 16\n",
      "Starting batch: 17\n",
      "Starting batch: 18\n",
      "Starting batch: 19\n",
      "Starting batch: 20\n",
      "Starting batch: 21\n",
      "Starting batch: 22\n",
      "Starting batch: 23\n",
      "Starting batch: 24\n",
      "Starting batch: 25\n",
      "Starting batch: 26\n",
      "Starting batch: 27\n",
      "Starting batch: 28\n",
      "Starting batch: 29\n",
      "Starting batch: 30\n",
      "Starting batch: 31\n",
      "Starting batch: 32\n",
      "Starting batch: 33\n",
      "Starting batch: 34\n",
      "Starting batch: 35\n",
      "Starting batch: 36\n",
      "Starting batch: 37\n",
      "Starting batch: 38\n",
      "Starting batch: 39\n",
      "Starting batch: 40\n",
      "Starting batch: 41\n",
      "Starting batch: 42\n",
      "Starting batch: 43\n",
      "Starting batch: 44\n",
      "Starting batch: 45\n",
      "Starting batch: 46\n",
      "Starting batch: 47\n",
      "Starting batch: 48\n",
      "Starting batch: 49\n",
      "Starting batch: 50\n",
      "Starting batch: 51\n",
      "Starting batch: 52\n",
      "Starting batch: 53\n",
      "Starting batch: 54\n",
      "Starting batch: 55\n",
      "Starting batch: 56\n",
      "Starting batch: 57\n",
      "Starting batch: 58\n",
      "Saving: Groups/Group_3/group_3_batch_0.txt\n",
      "Saving: Groups/Group_3/group_3_batch_6.txt\n",
      "Saving: Groups/Group_3/group_3_batch_3.txt\n",
      "Saving: Groups/Group_3/group_3_batch_4.txt\n",
      "Saving: Groups/Group_3/group_3_batch_5.txt\n",
      "Saving: Groups/Group_3/group_3_batch_9.txt\n",
      "Saving: Groups/Group_3/group_3_batch_1.txt\n",
      "Saving: Groups/Group_3/group_3_batch_7.txt\n",
      "Saving: Groups/Group_3/group_3_batch_2.txt\n",
      "Saving: Groups/Group_3/group_3_batch_8.txt\n",
      "Saving: Groups/Group_3/group_3_batch_10.txt\n",
      "Saving: Groups/Group_3/group_3_batch_11.txt\n",
      "Saving: Groups/Group_3/group_3_batch_13.txt\n",
      "Saving: Groups/Group_3/group_3_batch_12.txt\n",
      "Saving: Groups/Group_3/group_3_batch_18.txt\n",
      "Saving: Groups/Group_3/group_3_batch_17.txt\n",
      "Saving: Groups/Group_3/group_3_batch_14.txt\n",
      "Saving: Groups/Group_3/group_3_batch_16.txt\n",
      "Saving: Groups/Group_3/group_3_batch_19.txt\n",
      "Saving: Groups/Group_3/group_3_batch_15.txt\n",
      "Saving: Groups/Group_3/group_3_batch_23.txt\n",
      "Saving: Groups/Group_3/group_3_batch_21.txt\n",
      "Saving: Groups/Group_3/group_3_batch_20.txt\n",
      "Saving: Groups/Group_3/group_3_batch_24.txt\n",
      "Saving: Groups/Group_3/group_3_batch_26.txt\n",
      "Saving: Groups/Group_3/group_3_batch_22.txt\n",
      "Saving: Groups/Group_3/group_3_batch_25.txt\n",
      "Saving: Groups/Group_3/group_3_batch_27.txt\n",
      "Saving: Groups/Group_3/group_3_batch_28.txt\n",
      "Saving: Groups/Group_3/group_3_batch_29.txt\n",
      "Saving: Groups/Group_3/group_3_batch_30.txt\n",
      "Saving: Groups/Group_3/group_3_batch_31.txt\n",
      "Saving: Groups/Group_3/group_3_batch_35.txt\n",
      "Saving: Groups/Group_3/group_3_batch_33.txt\n",
      "Saving: Groups/Group_3/group_3_batch_32.txt\n",
      "Saving: Groups/Group_3/group_3_batch_36.txt\n",
      "Saving: Groups/Group_3/group_3_batch_37.txt\n",
      "Saving: Groups/Group_3/group_3_batch_34.txt\n",
      "Saving: Groups/Group_3/group_3_batch_38.txt\n",
      "Saving: Groups/Group_3/group_3_batch_39.txt\n",
      "Saving: Groups/Group_3/group_3_batch_40.txt\n",
      "Saving: Groups/Group_3/group_3_batch_41.txt\n",
      "Saving: Groups/Group_3/group_3_batch_42.txt\n",
      "Saving: Groups/Group_3/group_3_batch_45.txt\n",
      "Saving: Groups/Group_3/group_3_batch_43.txt\n",
      "Saving: Groups/Group_3/group_3_batch_48.txt\n",
      "Saving: Groups/Group_3/group_3_batch_47.txt\n",
      "Error communicating with OpenAI: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f4c3e76ff7746e817a15aad0c0777b8 in your message.)\n",
      "Saving: Groups/Group_3/group_3_batch_46.txt\n",
      "Saving: Groups/Group_3/group_3_batch_44.txt\n",
      "Saving: Groups/Group_3/group_3_batch_50.txt\n",
      "Saving: Groups/Group_3/group_3_batch_49.txt\n",
      "Saving: Groups/Group_3/group_3_batch_52.txt\n",
      "Saving: Groups/Group_3/group_3_batch_51.txt\n",
      "Saving: Groups/Group_3/group_3_batch_53.txt\n",
      "Saving: Groups/Group_3/group_3_batch_54.txt\n",
      "Saving: Groups/Group_3/group_3_batch_56.txt\n",
      "Saving: Groups/Group_3/group_3_batch_57.txt\n",
      "Saving: Groups/Group_3/group_3_batch_58.txt\n",
      "Saving: Groups/Group_3/group_3_batch_55.txt\n",
      "\n",
      "\n",
      "Starting Group: 4\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Starting batch: 9\n",
      "Starting batch: 10\n",
      "Starting batch: 11\n",
      "Starting batch: 12\n",
      "Starting batch: 13\n",
      "Starting batch: 14\n",
      "Starting batch: 15\n",
      "Starting batch: 16\n",
      "Starting batch: 17\n",
      "Starting batch: 18\n",
      "Starting batch: 19\n",
      "Starting batch: 20\n",
      "Starting batch: 21\n",
      "Starting batch: 22\n",
      "Starting batch: 23\n",
      "Starting batch: 24\n",
      "Starting batch: 25\n",
      "Starting batch: 26\n",
      "Starting batch: 27\n",
      "Starting batch: 28\n",
      "Starting batch: 29\n",
      "Saving: Groups/Group_4/group_4_batch_5.txt\n",
      "Saving: Groups/Group_4/group_4_batch_8.txt\n",
      "Saving: Groups/Group_4/group_4_batch_9.txt\n",
      "Saving: Groups/Group_4/group_4_batch_1.txt\n",
      "Saving: Groups/Group_4/group_4_batch_6.txt\n",
      "Saving: Groups/Group_4/group_4_batch_3.txt\n",
      "Saving: Groups/Group_4/group_4_batch_7.txt\n",
      "Saving: Groups/Group_4/group_4_batch_4.txt\n",
      "Saving: Groups/Group_4/group_4_batch_2.txt\n",
      "Saving: Groups/Group_4/group_4_batch_0.txt\n",
      "Saving: Groups/Group_4/group_4_batch_11.txt\n",
      "Saving: Groups/Group_4/group_4_batch_12.txt\n",
      "Saving: Groups/Group_4/group_4_batch_14.txt\n",
      "Saving: Groups/Group_4/group_4_batch_13.txt\n",
      "Saving: Groups/Group_4/group_4_batch_16.txt\n",
      "Saving: Groups/Group_4/group_4_batch_10.txt\n",
      "Saving: Groups/Group_4/group_4_batch_18.txt\n",
      "Saving: Groups/Group_4/group_4_batch_15.txt\n",
      "Saving: Groups/Group_4/group_4_batch_19.txt\n",
      "Saving: Groups/Group_4/group_4_batch_17.txt\n",
      "Saving: Groups/Group_4/group_4_batch_20.txt\n",
      "Saving: Groups/Group_4/group_4_batch_22.txt\n",
      "Saving: Groups/Group_4/group_4_batch_23.txt\n",
      "Saving: Groups/Group_4/group_4_batch_21.txt\n",
      "Saving: Groups/Group_4/group_4_batch_26.txt\n",
      "Saving: Groups/Group_4/group_4_batch_29.txt\n",
      "Saving: Groups/Group_4/group_4_batch_24.txt\n",
      "Saving: Groups/Group_4/group_4_batch_25.txt\n",
      "Saving: Groups/Group_4/group_4_batch_27.txt\n",
      "Saving: Groups/Group_4/group_4_batch_28.txt\n",
      "\n",
      "\n",
      "Starting Group: 5\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Saving: Groups/Group_5/group_5_batch_1.txt\n",
      "Saving: Groups/Group_5/group_5_batch_3.txt\n",
      "Saving: Groups/Group_5/group_5_batch_0.txt\n",
      "Saving: Groups/Group_5/group_5_batch_2.txt\n",
      "\n",
      "\n",
      "Starting Group: 6\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Starting batch: 9\n",
      "Starting batch: 10\n",
      "Starting batch: 11\n",
      "Starting batch: 12\n",
      "Starting batch: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7d7761caa68d3f46a184a7c6bea7ca56 in your message.)\n",
      "Saving: Groups/Group_6/group_6_batch_2.txt\n",
      "Saving: Groups/Group_6/group_6_batch_5.txt\n",
      "Saving: Groups/Group_6/group_6_batch_0.txt\n",
      "Saving: Groups/Group_6/group_6_batch_7.txt\n",
      "Saving: Groups/Group_6/group_6_batch_6.txt\n",
      "Saving: Groups/Group_6/group_6_batch_8.txt\n",
      "Saving: Groups/Group_6/group_6_batch_4.txt\n",
      "Saving: Groups/Group_6/group_6_batch_3.txt\n",
      "Saving: Groups/Group_6/group_6_batch_9.txt\n",
      "Saving: Groups/Group_6/group_6_batch_1.txt\n",
      "Saving: Groups/Group_6/group_6_batch_10.txt\n",
      "Saving: Groups/Group_6/group_6_batch_13.txt\n",
      "Saving: Groups/Group_6/group_6_batch_12.txt\n",
      "Saving: Groups/Group_6/group_6_batch_11.txt\n",
      "\n",
      "\n",
      "Starting Group: 7\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Error communicating with OpenAI: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c015a7efe1c857f245ce418b3b5421df in your message.)\n",
      "Saving: Groups/Group_7/group_7_batch_1.txt\n",
      "Saving: Groups/Group_7/group_7_batch_0.txt\n",
      "\n",
      "\n",
      "Starting Group: 8\n",
      "Starting batch: 0\n",
      "Saving: Groups/Group_8/group_8_batch_0.txt\n",
      "\n",
      "\n",
      "Starting Group: 9\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Saving: Groups/Group_9/group_9_batch_3.txt\n",
      "Saving: Groups/Group_9/group_9_batch_1.txt\n",
      "Saving: Groups/Group_9/group_9_batch_4.txt\n",
      "Saving: Groups/Group_9/group_9_batch_2.txt\n",
      "Saving: Groups/Group_9/group_9_batch_5.txt\n",
      "Saving: Groups/Group_9/group_9_batch_0.txt\n",
      "\n",
      "\n",
      "Starting Group: 10\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n"
     ]
    }
   ],
   "source": [
    "group_count = 2 \n",
    "for original_dict in test:\n",
    "    \n",
    "    print(\"Starting Group:\", group_count)\n",
    "    group_size = original_dict['group_size']\n",
    "\n",
    "    # Remove the 'group_size' key from the new dictionary\n",
    "    del original_dict['group_size']\n",
    "    original_dict['place_of_residence'] = 'Montana, United States'\n",
    "\n",
    "    import concurrent.futures\n",
    "\n",
    "    batch_size = 5\n",
    "    max_workers = 10\n",
    "\n",
    "    # Calculate the number of full batches\n",
    "    full_batches = group_size // batch_size\n",
    "\n",
    "    # Calculate the number of remaining objects\n",
    "    remaining_objects = group_size % batch_size\n",
    "\n",
    "    personas = []\n",
    "\n",
    "    # Create a ThreadPoolExecutor with max_workers\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Create full batches of objects\n",
    "        for i in range(full_batches):\n",
    "            executor.submit(generate_and_save_persona, i, group_count)\n",
    "            print(\"Starting batch:\", str(i))\n",
    "        # Create remaining objects\n",
    "        if remaining_objects > 0:\n",
    "            executor.submit(generate_and_save_persona, full_batches, group_count)\n",
    "            print(\"Starting batch:\", str(full_batches))\n",
    "    \n",
    "    group_count += 1\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992a2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Saving: Groups/group_1_batch_0.txt\n"
     ]
    }
   ],
   "source": [
    "for original_dict in test:\n",
    "    group_count = 1 \n",
    "    group_size = original_dict['group_size']\n",
    "\n",
    "    # Remove the 'group_size' key from the new dictionary\n",
    "    del original_dict['group_size']\n",
    "    original_dict['place_of_residence'] = 'Montana, United States'\n",
    "\n",
    "    batch_size = 5\n",
    "\n",
    "    # Calculate the number of full batches\n",
    "    full_batches = group_size // batch_size\n",
    "\n",
    "    # Calculate the number of remaining objects\n",
    "    remaining_objects = group_size % batch_size\n",
    "\n",
    "    personas = []\n",
    "    \n",
    "    # Create full batches of objects\n",
    "    for i in range(full_batches):\n",
    "        persona_gen_role = GPT.open_file(\"Prompts/persona_gen_groups_v1.txt\")\n",
    "\n",
    "        tags = {\n",
    "            '<<BATCH>>': str(batch_size),\n",
    "            '<<GROUP>>': str(original_dict),\n",
    "            '<<NUM>>': str(i),\n",
    "        }\n",
    "\n",
    "        persona_text = GPT.generalized_gpt_prompt(\"Prompts/gen_by_group.txt\", tags, engine = 'gpt-4', role = persona_gen_role)\n",
    "        \n",
    "        file_path = f\"Groups/group_{group_count}_batch_{i}.txt\"\n",
    "        print(\"Saving:\", file_path)\n",
    "        GPT.save_file(file_path, persona_text)\n",
    "    \n",
    "\n",
    "    # Create remaining objects\n",
    "    if remaining_objects > 0:\n",
    "        persona_gen_role = GPT.open_file(\"Prompts/persona_gen_groups_v1.txt\")\n",
    "\n",
    "        tags = {\n",
    "            '<<BATCH>>': str(remaining_objects),\n",
    "            '<<GROUP>>': str(original_dict),\n",
    "            '<<NUM>>': str(full_batches),\n",
    "        }\n",
    "\n",
    "        persona_text = GPT.generalized_gpt_prompt(\"Prompts/gen_by_group.txt\", tags, engine = 'gpt-4', role = persona_gen_role)\n",
    "        file_path = f\"Groups/group_{group_count}_batch_{full_batches}.txt\"\n",
    "        print(\"Saving:\", file_path)\n",
    "        GPT.save_file(file_path, persona_text)\n",
    "    \n",
    "    group_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a5c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
