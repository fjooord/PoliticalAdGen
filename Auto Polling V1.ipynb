{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e20385",
   "metadata": {},
   "source": [
    "# Auto Polling\n",
    "    - This notebook will serve the following pipeline\n",
    "    - Ingest a demographic data, like the census of an area\n",
    "        - Create groups that will in total represent the population\n",
    "            - IE 100/1000 white women ages 20-30\n",
    "        - Turn the groups into personas\n",
    "            - For each group, use chat gpt to make that many personas of people\n",
    "            - Save personas for later use\n",
    "    - Create a survey based on the political landscape of the area\n",
    "        - Feed in the data and make survey\n",
    "        - Could make multiple surveys and have them be specific to the demographic\n",
    "    - Give survey to the personas\n",
    "        - For each persona, have them take the survey, save results\n",
    "    - Process results to determine the most important issues to make ads for\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f276369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.Chat_GPT_Funcs as GPT\n",
    "import concurrent.futures\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f335319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = [\n",
    "#   {\n",
    "#     \"group_size\": 294,\n",
    "#     \"age\": \"18-64\",\n",
    "#     \"gender\": \"Female\",\n",
    "#     \"ethnicity\": \"White\",\n",
    "#     \"income_levels\": \"$20,000 - $50,000\",\n",
    "#     \"employment_status\": \"In civilian labor force (62.9%)\",\n",
    "#     \"marital_status\": \"Not specified\",\n",
    "#     \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "#   },\n",
    "\"\"\"\n",
    "test = [\n",
    "  {\n",
    "    \"group_size\": 146,\n",
    "    \"age\": \"65 and over\",\n",
    "    \"gender\": \"Female\",\n",
    "    \"ethnicity\": \"White\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not in civilian labor force\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 294,\n",
    "    \"age\": \"18-64\",\n",
    "    \"gender\": \"Male\",\n",
    "    \"ethnicity\": \"White\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"In civilian labor force (62.9%)\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 146,\n",
    "    \"age\": \"65 and over\",\n",
    "    \"gender\": \"Male\",\n",
    "    \"ethnicity\": \"White\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not in civilian labor force\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "    \"\"\"\n",
    "test = [\n",
    "  {\n",
    "    \"group_size\": 20,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Black or African American\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 66,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"American Indian and Alaska Native\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 10,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Asian\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 1,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Native Hawaiian and Other Pacific Islander\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 30,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Two or More Races\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  },\n",
    "  {\n",
    "    \"group_size\": 43,\n",
    "    \"age\": \"18 and over\",\n",
    "    \"gender\": \"Not specified\",\n",
    "    \"ethnicity\": \"Hispanic or Latino\",\n",
    "    \"income_levels\": \"$20,000 - $50,000\",\n",
    "    \"employment_status\": \"Not specified\",\n",
    "    \"marital_status\": \"Not specified\",\n",
    "    \"education_level\": \"High school graduate or higher (94.4%)\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cdddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee73fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_persona(i, group_count):\n",
    "    persona_gen_role = GPT.open_file(\"Prompts/persona_gen_groups_v1.txt\")\n",
    "\n",
    "    tags = {\n",
    "        '<<BATCH>>': str(batch_size),\n",
    "        '<<GROUP>>': str(original_dict),\n",
    "        '<<NUM>>': str(i),\n",
    "    }\n",
    "\n",
    "    persona_text = GPT.generalized_gpt_prompt(\"Prompts/gen_by_group.txt\", tags, engine='gpt-4', role=persona_gen_role)\n",
    "    \n",
    "    parent_path = f\"Groups/Group_{group_count}/\"\n",
    "    create_directory_if_not_exists(parent_path)\n",
    "    \n",
    "    file_path = parent_path + f\"group_{group_count}_batch_{i}.txt\"\n",
    "    print(\"Saving:\", file_path)\n",
    "    GPT.save_file(file_path, persona_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf1af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Group: 5\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Saving: Groups/Group_5/group_5_batch_1.txt\n",
      "Saving: Groups/Group_5/group_5_batch_3.txt\n",
      "Saving: Groups/Group_5/group_5_batch_0.txt\n",
      "Saving: Groups/Group_5/group_5_batch_2.txt\n",
      "\n",
      "\n",
      "Starting Group: 6\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Starting batch: 9\n",
      "Starting batch: 10\n",
      "Starting batch: 11\n",
      "Starting batch: 12\n",
      "Starting batch: 13\n",
      "Error communicating with OpenAI: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dff06c81cd83cb110c77df2b1c6238ef in your message.)\n",
      "Saving: Groups/Group_6/group_6_batch_2.txt\n",
      "Saving: Groups/Group_6/group_6_batch_4.txt\n",
      "Saving: Groups/Group_6/group_6_batch_0.txt\n",
      "Saving: Groups/Group_6/group_6_batch_5.txt\n",
      "Saving: Groups/Group_6/group_6_batch_3.txt\n",
      "Saving: Groups/Group_6/group_6_batch_7.txt\n",
      "Saving: Groups/Group_6/group_6_batch_6.txt\n",
      "Saving: Groups/Group_6/group_6_batch_9.txt\n",
      "Saving: Groups/Group_6/group_6_batch_1.txt\n",
      "Saving: Groups/Group_6/group_6_batch_8.txt\n",
      "Saving: Groups/Group_6/group_6_batch_10.txt\n",
      "Saving: Groups/Group_6/group_6_batch_11.txt\n",
      "Saving: Groups/Group_6/group_6_batch_13.txt\n",
      "Saving: Groups/Group_6/group_6_batch_12.txt\n",
      "\n",
      "\n",
      "Starting Group: 7\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Saving: Groups/Group_7/group_7_batch_1.txt\n",
      "Saving: Groups/Group_7/group_7_batch_0.txt\n",
      "\n",
      "\n",
      "Starting Group: 8\n",
      "Starting batch: 0\n",
      "Saving: Groups/Group_8/group_8_batch_0.txt\n",
      "\n",
      "\n",
      "Starting Group: 9\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Saving: Groups/Group_9/group_9_batch_3.txt\n",
      "Saving: Groups/Group_9/group_9_batch_1.txt\n",
      "Saving: Groups/Group_9/group_9_batch_0.txt\n",
      "Saving: Groups/Group_9/group_9_batch_5.txt\n",
      "Saving: Groups/Group_9/group_9_batch_2.txt\n",
      "Saving: Groups/Group_9/group_9_batch_4.txt\n",
      "\n",
      "\n",
      "Starting Group: 10\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Saving: Groups/Group_10/group_10_batch_8.txt\n",
      "Saving: Groups/Group_10/group_10_batch_1.txt\n",
      "Saving: Groups/Group_10/group_10_batch_7.txt\n",
      "Saving: Groups/Group_10/group_10_batch_6.txt\n",
      "Saving: Groups/Group_10/group_10_batch_3.txt\n",
      "Saving: Groups/Group_10/group_10_batch_0.txt\n",
      "Saving: Groups/Group_10/group_10_batch_5.txt\n",
      "Saving: Groups/Group_10/group_10_batch_2.txt\n",
      "Saving: Groups/Group_10/group_10_batch_4.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_count = 5\n",
    "for original_dict in test:\n",
    "    \n",
    "    print(\"Starting Group:\", group_count)\n",
    "    group_size = original_dict['group_size']\n",
    "\n",
    "    # Remove the 'group_size' key from the new dictionary\n",
    "    del original_dict['group_size']\n",
    "    original_dict['place_of_residence'] = 'Montana, United States'\n",
    "\n",
    "    import concurrent.futures\n",
    "\n",
    "    batch_size = 5\n",
    "    max_workers = 10\n",
    "\n",
    "    # Calculate the number of full batches\n",
    "    full_batches = group_size // batch_size\n",
    "\n",
    "    # Calculate the number of remaining objects\n",
    "    remaining_objects = group_size % batch_size\n",
    "\n",
    "    personas = []\n",
    "\n",
    "    # Create a ThreadPoolExecutor with max_workers\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Create full batches of objects\n",
    "        for i in range(full_batches):\n",
    "            executor.submit(generate_and_save_persona, i, group_count)\n",
    "            print(\"Starting batch:\", str(i))\n",
    "        # Create remaining objects\n",
    "        if remaining_objects > 0:\n",
    "            executor.submit(generate_and_save_persona, full_batches, group_count)\n",
    "            print(\"Starting batch:\", str(full_batches))\n",
    "    \n",
    "    group_count += 1\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6a3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_paragraph(persona):\n",
    "    priorities = ', '.join(persona[\"Top Priorities\"])\n",
    "    pain_points = ', '.join(persona[\"Pain points\"])\n",
    "    return (f\"Your name is {persona['Name']}, you are a {persona['Age']} year old {persona['Gender']}. \"\n",
    "            f\"You identify as {persona['Ethnicity']}, and your annual income is ${persona['Income']}. \"\n",
    "            f\"Your marital status is {persona['Marital Status']}, and your highest level of education is {persona['Education Level']}. \"\n",
    "            f\"You work as a {persona['Occupation']}. You are described as '{persona['Description']}'. \"\n",
    "            f\"Your top priorities are {priorities}. You are facing some challenges, including {pain_points}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54e2e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups/Group_1/group_1_batch_28.txt\n",
      "Groups/Group_1/group_1_batch_14.txt\n",
      "Groups/Group_1/group_1_batch_15.txt\n",
      "Groups/Group_1/group_1_batch_29.txt\n",
      "Groups/Group_1/group_1_batch_17.txt\n",
      "Groups/Group_1/group_1_batch_16.txt\n",
      "Groups/Group_1/group_1_batch_12.txt\n",
      "Groups/Group_1/group_1_batch_13.txt\n",
      "Groups/Group_1/group_1_batch_11.txt\n",
      "Groups/Group_1/group_1_batch_39.txt\n",
      "Groups/Group_1/group_1_batch_38.txt\n",
      "Groups/Group_1/group_1_batch_10.txt\n",
      "Groups/Group_1/group_1_batch_48.txt\n",
      "Groups/Group_1/group_1_batch_49.txt\n",
      "Groups/Group_1/group_1_batch_8.txt\n",
      "Groups/Group_1/group_1_batch_58.txt\n",
      "Groups/Group_1/group_1_batch_9.txt\n",
      "Groups/Group_1/group_1_batch_7.txt\n",
      "Groups/Group_1/group_1_batch_42.txt\n",
      "Groups/Group_1/group_1_batch_56.txt\n",
      "Groups/Group_1/group_1_batch_57.txt\n",
      "Groups/Group_1/group_1_batch_43.txt\n",
      "Groups/Group_1/group_1_batch_6.txt\n",
      "Groups/Group_1/group_1_batch_4.txt\n",
      "Groups/Group_1/group_1_batch_55.txt\n",
      "Groups/Group_1/group_1_batch_41.txt\n",
      "Groups/Group_1/group_1_batch_40.txt\n",
      "Groups/Group_1/group_1_batch_54.txt\n",
      "Groups/Group_1/group_1_batch_5.txt\n",
      "Groups/Group_1/group_1_batch_50.txt\n",
      "Groups/Group_1/group_1_batch_44.txt\n",
      "Groups/Group_1/group_1_batch_1.txt\n",
      "Groups/Group_1/group_1_batch_0.txt\n",
      "Groups/Group_1/group_1_batch_45.txt\n",
      "Groups/Group_1/group_1_batch_51.txt\n",
      "Groups/Group_1/group_1_batch_47.txt\n",
      "Groups/Group_1/group_1_batch_53.txt\n",
      "Groups/Group_1/group_1_batch_2.txt\n",
      "Groups/Group_1/group_1_batch_3.txt\n",
      "Groups/Group_1/group_1_batch_52.txt\n",
      "Groups/Group_1/group_1_batch_46.txt\n",
      "Groups/Group_1/group_1_batch_21.txt\n",
      "Groups/Group_1/group_1_batch_35.txt\n",
      "Groups/Group_1/group_1_batch_34.txt\n",
      "Groups/Group_1/group_1_batch_20.txt\n",
      "Groups/Group_1/group_1_batch_36.txt\n",
      "Groups/Group_1/group_1_batch_22.txt\n",
      "Groups/Group_1/group_1_batch_23.txt\n",
      "Groups/Group_1/group_1_batch_37.txt\n",
      "Groups/Group_1/group_1_batch_33.txt\n",
      "Groups/Group_1/group_1_batch_27.txt\n",
      "Groups/Group_1/group_1_batch_26.txt\n",
      "Groups/Group_1/group_1_batch_32.txt\n",
      "Groups/Group_1/group_1_batch_24.txt\n",
      "Groups/Group_1/group_1_batch_30.txt\n",
      "Groups/Group_1/group_1_batch_18.txt\n",
      "Groups/Group_1/group_1_batch_19.txt\n",
      "Groups/Group_1/group_1_batch_31.txt\n",
      "Groups/Group_1/group_1_batch_25.txt\n",
      "Groups/Group_2/group_2_batch_20.txt\n",
      "Groups/Group_2/group_2_batch_21.txt\n",
      "Groups/Group_2/group_2_batch_23.txt\n",
      "Groups/Group_2/group_2_batch_9.txt\n",
      "Groups/Group_2/group_2_batch_8.txt\n",
      "Groups/Group_2/group_2_batch_22.txt\n",
      "Groups/Group_2/group_2_batch_26.txt\n",
      "Groups/Group_2/group_2_batch_27.txt\n",
      "Groups/Group_2/group_2_batch_19.txt\n",
      "Groups/Group_2/group_2_batch_25.txt\n",
      "Groups/Group_2/group_2_batch_24.txt\n",
      "Groups/Group_2/group_2_batch_18.txt\n",
      "Groups/Group_2/group_2_batch_15.txt\n",
      "Groups/Group_2/group_2_batch_29.txt\n",
      "Groups/Group_2/group_2_batch_3.txt\n",
      "Groups/Group_2/group_2_batch_2.txt\n",
      "Groups/Group_2/group_2_batch_28.txt\n",
      "Groups/Group_2/group_2_batch_14.txt\n",
      "Groups/Group_2/group_2_batch_16.txt\n",
      "Groups/Group_2/group_2_batch_0.txt\n",
      "Groups/Group_2/group_2_batch_1.txt\n",
      "Groups/Group_2/group_2_batch_17.txt\n",
      "Groups/Group_2/group_2_batch_13.txt\n",
      "Groups/Group_2/group_2_batch_5.txt\n",
      "Groups/Group_2/group_2_batch_4.txt\n",
      "Groups/Group_2/group_2_batch_12.txt\n",
      "Groups/Group_2/group_2_batch_10.txt\n",
      "Groups/Group_2/group_2_batch_6.txt\n",
      "Groups/Group_2/group_2_batch_7.txt\n",
      "Groups/Group_2/group_2_batch_11.txt\n",
      "Groups/Group_3/group_3_batch_33.txt\n",
      "Groups/Group_3/group_3_batch_27.txt\n",
      "Groups/Group_3/group_3_batch_26.txt\n",
      "Groups/Group_3/group_3_batch_32.txt\n",
      "Groups/Group_3/group_3_batch_24.txt\n",
      "Groups/Group_3/group_3_batch_30.txt\n",
      "Groups/Group_3/group_3_batch_18.txt\n",
      "Groups/Group_3/group_3_batch_19.txt\n",
      "Groups/Group_3/group_3_batch_31.txt\n",
      "Groups/Group_3/group_3_batch_25.txt\n",
      "Groups/Group_3/group_3_batch_21.txt\n",
      "Groups/Group_3/group_3_batch_35.txt\n",
      "Groups/Group_3/group_3_batch_34.txt\n",
      "Groups/Group_3/group_3_batch_20.txt\n",
      "Groups/Group_3/group_3_batch_36.txt\n",
      "Groups/Group_3/group_3_batch_22.txt\n",
      "Groups/Group_3/group_3_batch_23.txt\n",
      "Groups/Group_3/group_3_batch_37.txt\n",
      "Groups/Group_3/group_3_batch_50.txt\n",
      "Groups/Group_3/group_3_batch_44.txt\n",
      "Groups/Group_3/group_3_batch_7.txt\n",
      "Groups/Group_3/group_3_batch_6.txt\n",
      "Groups/Group_3/group_3_batch_45.txt\n",
      "Groups/Group_3/group_3_batch_51.txt\n",
      "Groups/Group_3/group_3_batch_47.txt\n",
      "Groups/Group_3/group_3_batch_53.txt\n",
      "Groups/Group_3/group_3_batch_4.txt\n",
      "Groups/Group_3/group_3_batch_5.txt\n",
      "Groups/Group_3/group_3_batch_52.txt\n",
      "Groups/Group_3/group_3_batch_46.txt\n",
      "Groups/Group_3/group_3_batch_42.txt\n",
      "Groups/Group_3/group_3_batch_56.txt\n",
      "Groups/Group_3/group_3_batch_1.txt\n",
      "Groups/Group_3/group_3_batch_0.txt\n",
      "Groups/Group_3/group_3_batch_57.txt\n",
      "Groups/Group_3/group_3_batch_43.txt\n",
      "Groups/Group_3/group_3_batch_55.txt\n",
      "Groups/Group_3/group_3_batch_41.txt\n",
      "Groups/Group_3/group_3_batch_2.txt\n",
      "Groups/Group_3/group_3_batch_3.txt\n",
      "Groups/Group_3/group_3_batch_40.txt\n",
      "Groups/Group_3/group_3_batch_54.txt\n",
      "Groups/Group_3/group_3_batch_58.txt\n",
      "Groups/Group_3/group_3_batch_8.txt\n",
      "Groups/Group_3/group_3_batch_9.txt\n",
      "Groups/Group_3/group_3_batch_48.txt\n",
      "Groups/Group_3/group_3_batch_49.txt\n",
      "Groups/Group_3/group_3_batch_12.txt\n",
      "Groups/Group_3/group_3_batch_13.txt\n",
      "Groups/Group_3/group_3_batch_11.txt\n",
      "Groups/Group_3/group_3_batch_39.txt\n",
      "Groups/Group_3/group_3_batch_38.txt\n",
      "Groups/Group_3/group_3_batch_10.txt\n",
      "Groups/Group_3/group_3_batch_28.txt\n",
      "Groups/Group_3/group_3_batch_14.txt\n",
      "Groups/Group_3/group_3_batch_15.txt\n",
      "Groups/Group_3/group_3_batch_29.txt\n",
      "Groups/Group_3/group_3_batch_17.txt\n",
      "Groups/Group_3/group_3_batch_16.txt\n",
      "Groups/Group_4/group_4_batch_27.txt\n",
      "Groups/Group_4/group_4_batch_26.txt\n",
      "Groups/Group_4/group_4_batch_24.txt\n",
      "Groups/Group_4/group_4_batch_18.txt\n",
      "Groups/Group_4/group_4_batch_19.txt\n",
      "Groups/Group_4/group_4_batch_25.txt\n",
      "Groups/Group_4/group_4_batch_21.txt\n",
      "Groups/Group_4/group_4_batch_20.txt\n",
      "Groups/Group_4/group_4_batch_22.txt\n",
      "Groups/Group_4/group_4_batch_23.txt\n",
      "Groups/Group_4/group_4_batch_8.txt\n",
      "Groups/Group_4/group_4_batch_9.txt\n",
      "Groups/Group_4/group_4_batch_2.txt\n",
      "Groups/Group_4/group_4_batch_3.txt\n",
      "Groups/Group_4/group_4_batch_1.txt\n",
      "Groups/Group_4/group_4_batch_0.txt\n",
      "Groups/Group_4/group_4_batch_4.txt\n",
      "Groups/Group_4/group_4_batch_5.txt\n",
      "Groups/Group_4/group_4_batch_7.txt\n",
      "Groups/Group_4/group_4_batch_6.txt\n",
      "Groups/Group_4/group_4_batch_12.txt\n",
      "Groups/Group_4/group_4_batch_13.txt\n",
      "Groups/Group_4/group_4_batch_11.txt\n",
      "Groups/Group_4/group_4_batch_10.txt\n",
      "Groups/Group_4/group_4_batch_28.txt\n",
      "Groups/Group_4/group_4_batch_14.txt\n",
      "Groups/Group_4/group_4_batch_15.txt\n",
      "Groups/Group_4/group_4_batch_29.txt\n",
      "Groups/Group_4/group_4_batch_17.txt\n",
      "Groups/Group_4/group_4_batch_16.txt\n",
      "Replacement complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "parent_path = \"Groups/\"\n",
    "# Define the directories to go through\n",
    "directories = ['Groups/Group_1', 'Groups/Group_2', 'Groups/Group_3', 'Groups/Group_4']\n",
    "\n",
    "# Define the string to find and the string to replace it with\n",
    "find_string = '\"Nationality\": \"American\",'\n",
    "#find_string1 = '\"Nationality\": \"White\",'\n",
    "replace_string = '\"Ethnicity\": \"White\",'\n",
    "\n",
    "# For each directory\n",
    "for directory in directories:\n",
    "    # Use a wildcard (*) to find all .txt files in the directory\n",
    "    for file_name in glob.glob(directory + '/*.txt'):\n",
    "        print(file_name)\n",
    "        # Open each file in read mode to get the data\n",
    "        file_data = GPT.open_file(file_name)\n",
    "        \n",
    "        # Replace the find_string with replace_string\n",
    "        new_data = file_data.replace(find_string, replace_string)\n",
    "        new_data = new_data.replace(find_string1, replace_string)\n",
    "        \n",
    "        #print(new_data)\n",
    "        \n",
    "        # Open the file in write mode to overwrite the original data with the new data\n",
    "        GPT.save_file(file_name, new_data)\n",
    "\n",
    "print(\"Replacement complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fccc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
