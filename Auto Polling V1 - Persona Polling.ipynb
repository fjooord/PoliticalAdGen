{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ebe324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import Utils.Chat_GPT_Funcs as GPT\n",
    "import concurrent.futures\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37df5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/ehartford/WizardLM-7B-Uncensored\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your \",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc74d7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Model ehartford/WizardLM-7B-Uncensored is currently loading',\n",
       " 'estimated_time': 20.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304ff662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_paragraph(persona, residence):\n",
    "    priorities = persona[\"Top Priorities\"]\n",
    "    try:\n",
    "        pain_points = persona[\"Pain points\"]\n",
    "    except:\n",
    "        pain_points = persona[\"Pain Points\"]\n",
    "    \n",
    "    return (f\"Your name is {persona['Name']}, you are a {persona['Age']} year old {persona['Ethnicity']} {persona['Gender']}. \"\n",
    "            f\"You live in {residence} and your annual income is ${persona['Income']}. \"\n",
    "            f\"Your marital status is {persona['Marital Status']}, and your highest level of education is {persona['Education Level']}. \"\n",
    "            f\"You work as a {persona['Occupation']}. You are described as '{persona['Description']}'. \"\n",
    "            f\"Your top priorities are {priorities}. You are facing some challenges, including {pain_points}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35ba051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups/Group_0/group_0_batch_13.txt\n",
      "Groups/Group_0/group_0_batch_3.txt\n",
      "Groups/Group_0/group_0_batch_2.txt\n",
      "Groups/Group_0/group_0_batch_12.txt\n",
      "Groups/Group_0/group_0_batch_38.txt\n",
      "Groups/Group_0/group_0_batch_0.txt\n",
      "Groups/Group_0/group_0_batch_10.txt\n",
      "Groups/Group_0/group_0_batch_11.txt\n",
      "Groups/Group_0/group_0_batch_1.txt\n",
      "Groups/Group_0/group_0_batch_39.txt\n",
      "Groups/Group_0/group_0_batch_5.txt\n",
      "Groups/Group_0/group_0_batch_15.txt\n",
      "Groups/Group_0/group_0_batch_29.txt\n",
      "Groups/Group_0/group_0_batch_28.txt\n",
      "Groups/Group_0/group_0_batch_14.txt\n",
      "Groups/Group_0/group_0_batch_4.txt\n",
      "Groups/Group_0/group_0_batch_16.txt\n",
      "Groups/Group_0/group_0_batch_6.txt\n",
      "Groups/Group_0/group_0_batch_7.txt\n",
      "Groups/Group_0/group_0_batch_17.txt\n",
      "Groups/Group_0/group_0_batch_58.txt\n",
      "Groups/Group_0/group_0_batch_49.txt\n",
      "Groups/Group_0/group_0_batch_48.txt\n",
      "Groups/Group_0/group_0_batch_51.txt\n",
      "Groups/Group_0/group_0_batch_45.txt\n",
      "Groups/Group_0/group_0_batch_44.txt\n",
      "Groups/Group_0/group_0_batch_50.txt\n",
      "Groups/Group_0/group_0_batch_46.txt\n",
      "Groups/Group_0/group_0_batch_52.txt\n",
      "Groups/Group_0/group_0_batch_53.txt\n",
      "Groups/Group_0/group_0_batch_47.txt\n",
      "Groups/Group_0/group_0_batch_43.txt\n",
      "Groups/Group_0/group_0_batch_57.txt\n",
      "Groups/Group_0/group_0_batch_56.txt\n",
      "Groups/Group_0/group_0_batch_42.txt\n",
      "Groups/Group_0/group_0_batch_54.txt\n",
      "Groups/Group_0/group_0_batch_40.txt\n",
      "Groups/Group_0/group_0_batch_41.txt\n",
      "Groups/Group_0/group_0_batch_55.txt\n",
      "Groups/Group_0/group_0_batch_32.txt\n",
      "Groups/Group_0/group_0_batch_26.txt\n",
      "Groups/Group_0/group_0_batch_27.txt\n",
      "Groups/Group_0/group_0_batch_33.txt\n",
      "Groups/Group_0/group_0_batch_19.txt\n",
      "Groups/Group_0/group_0_batch_9.txt\n",
      "Groups/Group_0/group_0_batch_25.txt\n",
      "Groups/Group_0/group_0_batch_31.txt\n",
      "Groups/Group_0/group_0_batch_30.txt\n",
      "Groups/Group_0/group_0_batch_24.txt\n",
      "Groups/Group_0/group_0_batch_8.txt\n",
      "Groups/Group_0/group_0_batch_18.txt\n",
      "Groups/Group_0/group_0_batch_20.txt\n",
      "Groups/Group_0/group_0_batch_34.txt\n",
      "Groups/Group_0/group_0_batch_35.txt\n",
      "Groups/Group_0/group_0_batch_21.txt\n",
      "Groups/Group_0/group_0_batch_37.txt\n",
      "Groups/Group_0/group_0_batch_23.txt\n",
      "Groups/Group_0/group_0_batch_22.txt\n",
      "Groups/Group_0/group_0_batch_36.txt\n",
      "Num Personas in Group 0: 295\n",
      "Groups/Group_1/group_1_batch_28.txt\n",
      "Groups/Group_1/group_1_batch_14.txt\n",
      "Groups/Group_1/group_1_batch_15.txt\n",
      "Groups/Group_1/group_1_batch_29.txt\n",
      "Groups/Group_1/group_1_batch_17.txt\n",
      "Groups/Group_1/group_1_batch_16.txt\n",
      "Groups/Group_1/group_1_batch_12.txt\n",
      "Groups/Group_1/group_1_batch_13.txt\n",
      "Groups/Group_1/group_1_batch_11.txt\n",
      "Groups/Group_1/group_1_batch_10.txt\n",
      "Groups/Group_1/group_1_batch_8.txt\n",
      "Groups/Group_1/group_1_batch_9.txt\n",
      "Groups/Group_1/group_1_batch_7.txt\n",
      "Groups/Group_1/group_1_batch_6.txt\n",
      "Groups/Group_1/group_1_batch_4.txt\n",
      "Groups/Group_1/group_1_batch_5.txt\n",
      "Groups/Group_1/group_1_batch_1.txt\n",
      "Groups/Group_1/group_1_batch_0.txt\n",
      "Groups/Group_1/group_1_batch_2.txt\n",
      "Groups/Group_1/group_1_batch_3.txt\n",
      "Groups/Group_1/group_1_batch_21.txt\n",
      "Groups/Group_1/group_1_batch_20.txt\n",
      "Groups/Group_1/group_1_batch_22.txt\n",
      "Groups/Group_1/group_1_batch_23.txt\n",
      "Groups/Group_1/group_1_batch_27.txt\n",
      "Groups/Group_1/group_1_batch_26.txt\n",
      "Groups/Group_1/group_1_batch_24.txt\n",
      "Groups/Group_1/group_1_batch_18.txt\n",
      "Groups/Group_1/group_1_batch_19.txt\n",
      "Groups/Group_1/group_1_batch_25.txt\n",
      "Num Personas in Group 1: 150\n",
      "Groups/Group_2/group_2_batch_20.txt\n",
      "Groups/Group_2/group_2_batch_34.txt\n",
      "Groups/Group_2/group_2_batch_35.txt\n",
      "Groups/Group_2/group_2_batch_21.txt\n",
      "Groups/Group_2/group_2_batch_37.txt\n",
      "Groups/Group_2/group_2_batch_23.txt\n",
      "Groups/Group_2/group_2_batch_9.txt\n",
      "Groups/Group_2/group_2_batch_8.txt\n",
      "Groups/Group_2/group_2_batch_22.txt\n",
      "Groups/Group_2/group_2_batch_36.txt\n",
      "Groups/Group_2/group_2_batch_32.txt\n",
      "Groups/Group_2/group_2_batch_26.txt\n",
      "Groups/Group_2/group_2_batch_27.txt\n",
      "Groups/Group_2/group_2_batch_33.txt\n",
      "Groups/Group_2/group_2_batch_19.txt\n",
      "Groups/Group_2/group_2_batch_25.txt\n",
      "Groups/Group_2/group_2_batch_31.txt\n",
      "Groups/Group_2/group_2_batch_30.txt\n",
      "Groups/Group_2/group_2_batch_24.txt\n",
      "Groups/Group_2/group_2_batch_18.txt\n",
      "Groups/Group_2/group_2_batch_43.txt\n",
      "Groups/Group_2/group_2_batch_57.txt\n",
      "Groups/Group_2/group_2_batch_56.txt\n",
      "Groups/Group_2/group_2_batch_42.txt\n",
      "Groups/Group_2/group_2_batch_54.txt\n",
      "Groups/Group_2/group_2_batch_40.txt\n",
      "Groups/Group_2/group_2_batch_41.txt\n",
      "Groups/Group_2/group_2_batch_55.txt\n",
      "Groups/Group_2/group_2_batch_51.txt\n",
      "Groups/Group_2/group_2_batch_45.txt\n",
      "Groups/Group_2/group_2_batch_44.txt\n",
      "Groups/Group_2/group_2_batch_50.txt\n",
      "Groups/Group_2/group_2_batch_46.txt\n",
      "Groups/Group_2/group_2_batch_52.txt\n",
      "Groups/Group_2/group_2_batch_53.txt\n",
      "Groups/Group_2/group_2_batch_47.txt\n",
      "Groups/Group_2/group_2_batch_49.txt\n",
      "Groups/Group_2/group_2_batch_48.txt\n",
      "Groups/Group_2/group_2_batch_58.txt\n",
      "Groups/Group_2/group_2_batch_15.txt\n",
      "Groups/Group_2/group_2_batch_29.txt\n",
      "Groups/Group_2/group_2_batch_3.txt\n",
      "Groups/Group_2/group_2_batch_2.txt\n",
      "Groups/Group_2/group_2_batch_28.txt\n",
      "Groups/Group_2/group_2_batch_14.txt\n",
      "Groups/Group_2/group_2_batch_16.txt\n",
      "Groups/Group_2/group_2_batch_0.txt\n",
      "Groups/Group_2/group_2_batch_1.txt\n",
      "Groups/Group_2/group_2_batch_17.txt\n",
      "Groups/Group_2/group_2_batch_13.txt\n",
      "Groups/Group_2/group_2_batch_5.txt\n",
      "Groups/Group_2/group_2_batch_4.txt\n",
      "Groups/Group_2/group_2_batch_12.txt\n",
      "Groups/Group_2/group_2_batch_38.txt\n",
      "Groups/Group_2/group_2_batch_10.txt\n",
      "Groups/Group_2/group_2_batch_6.txt\n",
      "Groups/Group_2/group_2_batch_7.txt\n",
      "Groups/Group_2/group_2_batch_11.txt\n",
      "Groups/Group_2/group_2_batch_39.txt\n",
      "Num Personas in Group 2: 295\n",
      "Num Personas in Group 3: 0\n",
      "Groups/Group_4/group_4_batch_27.txt\n",
      "Groups/Group_4/group_4_batch_26.txt\n",
      "Groups/Group_4/group_4_batch_24.txt\n",
      "Groups/Group_4/group_4_batch_18.txt\n",
      "Groups/Group_4/group_4_batch_19.txt\n",
      "Groups/Group_4/group_4_batch_25.txt\n",
      "Groups/Group_4/group_4_batch_21.txt\n",
      "Groups/Group_4/group_4_batch_20.txt\n",
      "Groups/Group_4/group_4_batch_22.txt\n",
      "Groups/Group_4/group_4_batch_23.txt\n",
      "Groups/Group_4/group_4_batch_8.txt\n",
      "Groups/Group_4/group_4_batch_9.txt\n",
      "Groups/Group_4/group_4_batch_2.txt\n",
      "Groups/Group_4/group_4_batch_3.txt\n",
      "Groups/Group_4/group_4_batch_1.txt\n",
      "Groups/Group_4/group_4_batch_0.txt\n",
      "Groups/Group_4/group_4_batch_4.txt\n",
      "Groups/Group_4/group_4_batch_5.txt\n",
      "Groups/Group_4/group_4_batch_7.txt\n",
      "Groups/Group_4/group_4_batch_12.txt\n",
      "Groups/Group_4/group_4_batch_13.txt\n",
      "Groups/Group_4/group_4_batch_11.txt\n",
      "Groups/Group_4/group_4_batch_10.txt\n",
      "Groups/Group_4/group_4_batch_28.txt\n",
      "Groups/Group_4/group_4_batch_14.txt\n",
      "Groups/Group_4/group_4_batch_15.txt\n",
      "Groups/Group_4/group_4_batch_29.txt\n",
      "Groups/Group_4/group_4_batch_17.txt\n",
      "Groups/Group_4/group_4_batch_16.txt\n",
      "Num Personas in Group 4: 145\n",
      "Groups/Group_5/group_5_batch_0.txt\n",
      "Groups/Group_5/group_5_batch_1.txt\n",
      "Groups/Group_5/group_5_batch_3.txt\n",
      "Groups/Group_5/group_5_batch_2.txt\n",
      "Num Personas in Group 5: 20\n",
      "Groups/Group_6/group_6_batch_12.txt\n",
      "Groups/Group_6/group_6_batch_13.txt\n",
      "Groups/Group_6/group_6_batch_11.txt\n",
      "Groups/Group_6/group_6_batch_10.txt\n",
      "Groups/Group_6/group_6_batch_2.txt\n",
      "Groups/Group_6/group_6_batch_3.txt\n",
      "Groups/Group_6/group_6_batch_1.txt\n",
      "Groups/Group_6/group_6_batch_0.txt\n",
      "Groups/Group_6/group_6_batch_4.txt\n",
      "Groups/Group_6/group_6_batch_5.txt\n",
      "Groups/Group_6/group_6_batch_7.txt\n",
      "Groups/Group_6/group_6_batch_6.txt\n",
      "Groups/Group_6/group_6_batch_8.txt\n",
      "Groups/Group_6/group_6_batch_9.txt\n",
      "Num Personas in Group 6: 70\n",
      "Groups/Group_7/group_7_batch_0.txt\n",
      "Groups/Group_7/group_7_batch_1.txt\n",
      "Num Personas in Group 7: 10\n",
      "Groups/Group_8/group_8_batch_0.txt\n",
      "Num Personas in Group 8: 5\n",
      "Groups/Group_9/group_9_batch_0.txt\n",
      "Groups/Group_9/group_9_batch_1.txt\n",
      "Groups/Group_9/group_9_batch_3.txt\n",
      "Groups/Group_9/group_9_batch_2.txt\n",
      "Groups/Group_9/group_9_batch_5.txt\n",
      "Groups/Group_9/group_9_batch_4.txt\n",
      "Num Personas in Group 9: 30\n",
      "Groups/Group_10/group_10_batch_8.txt\n",
      "Groups/Group_10/group_10_batch_1.txt\n",
      "Groups/Group_10/group_10_batch_0.txt\n",
      "Groups/Group_10/group_10_batch_2.txt\n",
      "Groups/Group_10/group_10_batch_3.txt\n",
      "Groups/Group_10/group_10_batch_7.txt\n",
      "Groups/Group_10/group_10_batch_6.txt\n",
      "Groups/Group_10/group_10_batch_4.txt\n",
      "Groups/Group_10/group_10_batch_5.txt\n",
      "Num Personas in Group 10: 45\n"
     ]
    }
   ],
   "source": [
    "parent_path = \"Groups/\"\n",
    "# Define the directories to go through\n",
    "directories = ['Groups/Group_1', 'Groups/Group_2', 'Groups/Group_3', 'Groups/Group_4']\n",
    "\n",
    "personas = []\n",
    "for i in range(0,11):\n",
    "    group_p = []\n",
    "    # For each directory\n",
    "    # for directory in directories:\n",
    "\n",
    "    directory = f'Groups/Group_{i}'\n",
    "    # Use a wildcard (*) to find all .txt files in the directory\n",
    "    for file_name in glob.glob(directory + '/*.txt'):\n",
    "        print(file_name)\n",
    "        # Open each file in read mode to get the data\n",
    "        file_data = GPT.open_file(file_name)\n",
    "        try:\n",
    "            for data in json.loads(file_data):\n",
    "    #         for key, value in data.items():\n",
    "    #             print(f\"{key}: {value}\")\n",
    "                personas.append(dict_to_paragraph(data, 'Montana, United States'))\n",
    "                group_p.append(dict_to_paragraph(data, 'Montana, United States'))\n",
    "        except:\n",
    "            continue\n",
    "    print(f\"Num Personas in Group {i}:\", len(group_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0e5b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Personas: 1065\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Personas:\", len(personas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04af1a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Nancy Nichols, you are a 32 year old White Female. You live in Montana, United States and your annual income is $35000. Your marital status is Single, and your highest level of education is High school graduate. You work as a Retail Sales Associate. You are described as 'Nancy is a friendly and outgoing individual who enjoys working with people. She is passionate about helping customers find the perfect items and providing excellent customer service.'. Your top priorities are ['Affordable healthcare', 'Job security', 'Environmental protection']. You are facing some challenges, including ['Limited job opportunities in her area', 'Rising cost of living', 'Lack of affordable healthcare options'].\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19aa19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Nancy Nichols, you are a 32 year old White Female. You live in Montana, United States and your annual income is $35000. Your marital status is Single, and your highest level of education is High school graduate. You work as a Retail Sales Associate. You are described as 'Nancy is a friendly and outgoing individual who enjoys working with people. She is passionate about helping customers find the perfect items and providing excellent customer service.'. Your top priorities are ['Affordable healthcare', 'Job security', 'Environmental protection']. You are facing some challenges, including ['Limited job opportunities in her area', 'Rising cost of living', 'Lack of affordable healthcare options'].\n",
      "\n",
      "Your task is to answers survey questions provided be user input.\n",
      "\n",
      "When answering a question, really think about your beliefs, life situation, and all factors provided.\n",
      "\n",
      "Answer the questions as truthfully as possible, even if that means answering in a way that may not be ideal for the question giver.\n",
      "\n",
      "Thank you and good luck! Please answer the following question.\n",
      "Please only output your answer to the question.\n",
      "\n",
      "Question = Do you approve or disapprove of President Joe Biden's student loan forgiveness plan?\n",
      "Approve\n",
      "Disapprove\n",
      "Neither Approve/Disapprove\n",
      "0 Neither Approve/Disapprove.\n",
      "Total Prompt Tokens: 262\n",
      "Total Completion Tokens: 7\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "question = \"Do you plan to vote in the 2022 midterm election?\"\n",
    "\n",
    "question = \"At this point in time, do you approve or disapprove of President Joe Biden's performance in office?\\nApprove\\nDisapprove\\nNeither Approve/Disapprove\"\n",
    "\n",
    "question = \"Do you approve or disapprove of President Joe Biden's student loan forgiveness plan?\\nApprove\\nDisapprove\\nNeither Approve/Disapprove\"\n",
    "\n",
    "total_prompt_tokens = 0\n",
    "total_completion_tokens = 0\n",
    "\n",
    "\n",
    "def thread_func(i):\n",
    "    global total_prompt_tokens, total_completion_tokens\n",
    "    persona_role = GPT.open_file(f\"Prompts/Polling/persona_role.txt\").replace('<<PERSONA>>', personas[i])\n",
    "    question_in = GPT.open_file(\"Prompts/Polling/question_in.txt\").replace('<<QUESTION>>', question)\n",
    "    print(persona_role, question_in)\n",
    "    resp, usage = GPT.chat_gpt(question_in, engine = 'gpt-3.5-turbo' , role = persona_role, temp = 0.05, tokens = 50)\n",
    "    total_completion_tokens += usage['completion_tokens']\n",
    "    total_prompt_tokens += usage['prompt_tokens']\n",
    "    print(i, resp)\n",
    "    return resp\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    responses = list(executor.map(thread_func, range(1)))\n",
    "\n",
    "print(\"Total Prompt Tokens:\", total_prompt_tokens)\n",
    "print(\"Total Completion Tokens:\", total_completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d09a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes count:  1065\n",
      "No count:  0\n"
     ]
    }
   ],
   "source": [
    "yes_count = 0\n",
    "no_count = 0\n",
    "\n",
    "for response in responses:\n",
    "    if 'Yes' in response:\n",
    "        yes_count += 1\n",
    "    elif 'No' in response:\n",
    "        no_count += 1\n",
    "\n",
    "print(\"Yes count: \", yes_count)\n",
    "print(\"No count: \", no_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d046816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
