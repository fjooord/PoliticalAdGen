{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e20385",
   "metadata": {},
   "source": [
    "# Auto Polling\n",
    "    - The original persona generation worked, but the personas were too generic and didnt give a model context to \n",
    "        make accurate predictions of the beliefs of a person\n",
    "    - Now making a new pipeline that will create personas in different stages to \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f276369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.Chat_GPT_Funcs as GPT\n",
    "import concurrent.futures\n",
    "import os\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3935f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "alphabet_uppercase = list(string.ascii_uppercase)\n",
    "\n",
    "male_name_starts = ['Al', 'An', 'Be', 'Br', 'Ch', 'Da', 'De', 'Ed', 'Fr', 'Ge', 'Ha', 'Ja', 'Jo', 'Ke', 'Le', 'Ma', 'Mi', 'Ni', 'Pa', 'Ra', 'Ro', 'Sa', 'St', 'Th', 'To', 'Wi', 'Ba', 'Ca', 'Di', 'El', 'Gr', 'He', 'Ir', 'Je', 'Kr', 'Lu', 'Mo', 'Ne', 'Os', 'Ph', 'Qu', 'Ri', 'Se', 'Te', 'Va', 'Ze']\n",
    "female_name_starts = ['Ab', 'Al', 'Am', 'An', 'Be', 'Br', 'Ca', 'Ce', 'Ch', 'Cl', 'De', 'Di', 'El', 'Em', 'Es', 'Ev', 'Fl', 'Fr', 'Ge', 'Gr', 'Ha', 'He', 'Ir', 'Is', 'Ja', 'Je', 'Jo', 'Ju', 'Ka', 'Ke', 'La', 'Li', 'Ma', 'Me', 'Mi', 'Na', 'Ni', 'Ol', 'Pa', 'Pr', 'Ra', 'Re', 'Sa', 'Si', 'Ta', 'Vi']\n",
    "\n",
    "male_names = alphabet_uppercase + male_name_starts\n",
    "female_names = alphabet_uppercase + female_name_starts\n",
    "\n",
    "print(len(female_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd80a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Personas in Group 0: 295\n",
      "Num Personas in Group 1: 150\n",
      "Num Personas in Group 2: 295\n",
      "Num Personas in Group 3: 0\n",
      "Num Personas in Group 4: 145\n",
      "Num Personas in Group 5: 20\n",
      "Num Personas in Group 6: 70\n",
      "Num Personas in Group 7: 10\n",
      "Num Personas in Group 8: 5\n",
      "Num Personas in Group 9: 30\n",
      "Num Personas in Group 10: 45\n",
      "1065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'Alicia Brown',\n",
       " 'Age': 24,\n",
       " 'Gender': 'Female',\n",
       " 'Ethnicity': 'Black or African American',\n",
       " 'Income': 32000,\n",
       " 'Marital Status': 'Single',\n",
       " 'Education Level': 'High school graduate',\n",
       " 'Occupation': 'Retail Sales Associate',\n",
       " 'Description': 'A young woman who recently moved to Montana for a fresh start. She enjoys outdoor activities and is passionate about social justice.',\n",
       " 'Top Priorities': ['Affordable housing',\n",
       "  'Equal opportunities',\n",
       "  'Environmental protection'],\n",
       " 'Pain points': ['Limited job opportunities',\n",
       "  'Lack of diversity in her community',\n",
       "  'Student loan debt']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "parent_path = \"Groups/\"\n",
    "# Define the directories to go through\n",
    "directories = ['Groups/Group_1', 'Groups/Group_2', 'Groups/Group_3', 'Groups/Group_4']\n",
    "loc =  'Montana, United States'\n",
    "personas = []\n",
    "for i in range(0,11):\n",
    "    group_p = []\n",
    "    # For each directory\n",
    "    # for directory in directories:\n",
    "\n",
    "    directory = f'Groups/Group_{i}'\n",
    "    # Use a wildcard (*) to find all .txt files in the directory\n",
    "    for file_name in glob.glob(directory + '/*.txt'):\n",
    "        # Open each file in read mode to get the data\n",
    "        file_data = GPT.open_file(file_name)\n",
    "\n",
    "        for data in json.loads(file_data):\n",
    "#         for key, value in data.items():\n",
    "#             print(f\"{key}: {value}\")\n",
    "            personas.append(data)\n",
    "            group_p.append(data)\n",
    "    print(f\"Num Personas in Group {i}:\", len(group_p))\n",
    "\n",
    "\n",
    "print(len(personas))\n",
    "personas[900]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ddb50",
   "metadata": {},
   "source": [
    "# Distribute Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c74ff6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_age():\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.13:\n",
    "        return random.randint(18, 25)\n",
    "    elif random_number < 0.44:\n",
    "        return random.randint(25, 44)\n",
    "    elif random_number < 0.75:\n",
    "        return random.randint(45, 64)\n",
    "    else:\n",
    "        return random.randint(65, 87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in personas:\n",
    "    p['Age'] = str(distribute_age())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc16e7",
   "metadata": {},
   "source": [
    "# Distribute the Education Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ad305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_education_level():\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.60:\n",
    "        return \"High school graduate\"\n",
    "    elif random_number < 0.94:\n",
    "        return \"Bachelor's Degree or Higher\"\n",
    "    else:\n",
    "        return \"Less than a high school education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf4c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in personas:\n",
    "    p['Education Level'] = distribute_education_level()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97f780",
   "metadata": {},
   "source": [
    "# Distribute Politcal Affiliation\n",
    "    - Reps that say they are conservative at Con\n",
    "    - Reps say moderate, right leaning\n",
    "    - Anyone that contradicts or says dont know is moderate\n",
    "    - Dems that say moderate, left leaning\n",
    "    - Dems that say liberal, liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c24f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_party():\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.42:\n",
    "        return \"Conservative\"\n",
    "    elif random_number < 0.56:\n",
    "        return \"Right Leaning\"\n",
    "    elif random_number < 0.66:\n",
    "        return \"Moderate\"\n",
    "    elif random_number < 0.81:\n",
    "        return \"Left Leaning\"\n",
    "    else:\n",
    "        return \"Liberal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e218db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in personas:\n",
    "    p['Political Affiliation'] = distribute_party()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933f333",
   "metadata": {},
   "source": [
    "# Distribute Veteran Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eae54aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_veteran():\n",
    "    random_number = random.random()\n",
    "    \n",
    "    if random_number < 0.9:\n",
    "        return \"Not a Veteran\"\n",
    "    else:\n",
    "        return \"Is a Veteran\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc7ee2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in personas:\n",
    "    p['Veteran Status'] = distribute_party()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd80e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less than HS count: 60\n",
      "High school graduate count: 646\n",
      "Bachelor's Degree or Higher count: 359\n"
     ]
    }
   ],
   "source": [
    "def count_education_levels(strings):\n",
    "    count_less_than_hs = 0\n",
    "    count_high_school_grad = 0\n",
    "    count_bachelors_or_higher = 0\n",
    "\n",
    "    for string in strings:\n",
    "        if string == \"Less than a high school education\":\n",
    "            count_less_than_hs += 1\n",
    "        elif string == \"High school graduate\":\n",
    "            count_high_school_grad += 1\n",
    "        elif string == \"Bachelor's Degree or Higher\":\n",
    "            count_bachelors_or_higher += 1\n",
    "\n",
    "    return count_less_than_hs, count_high_school_grad, count_bachelors_or_higher\n",
    "\n",
    "# Example usage:\n",
    "string_list = [p['Education Level'] for p in personas]\n",
    "\n",
    "less_than_hs_count, high_school_grad_count, bachelors_or_higher_count = count_education_levels(string_list)\n",
    "print(\"Less than HS count:\", less_than_hs_count)\n",
    "print(\"High school graduate count:\", high_school_grad_count)\n",
    "print(\"Bachelor's Degree or Higher count:\", bachelors_or_higher_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346d525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b9e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_persona(i, group_count):\n",
    "  \n",
    "    persona_gen_role = GPT.open_file(\"Prompts/persona_gen_groups_v1.txt\")\n",
    "    \n",
    "    if group_count < 2:\n",
    "        name_rep = female_names[i%len(female_names)]\n",
    "    else:\n",
    "        name_rep = male_names[i%len(male_names)]\n",
    "        \n",
    "    tags = {\n",
    "        '<<BATCH>>': str(batch_size),\n",
    "        '<<GROUP>>': str(original_dict),\n",
    "        '<<START>>': name_rep,\n",
    "        '<<NUM>>': str(i),\n",
    "    }\n",
    "\n",
    "    persona_text = GPT.generalized_gpt_prompt(\"Prompts/gen_by_group.txt\", tags, tokens = 1500, engine='gpt-3.5-turbo', temp=0.25, role=persona_gen_role)\n",
    "    \n",
    "    parent_path = f\"Groups_v2/Group_{group_count}/\"\n",
    "    create_directory_if_not_exists(parent_path)\n",
    "    \n",
    "    file_path = parent_path + f\"group_{group_count}_batch_{i}.txt\"\n",
    "    print(\"Saving:\", file_path)\n",
    "    GPT.save_file(file_path, persona_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f894b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc5b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Group: 3\n",
      "Starting batch: 0\n",
      "Starting batch: 1\n",
      "Starting batch: 2\n",
      "Starting batch: 3\n",
      "Starting batch: 4\n",
      "Starting batch: 5\n",
      "Starting batch: 6\n",
      "Starting batch: 7\n",
      "Starting batch: 8\n",
      "Starting batch: 9\n",
      "Starting batch: 10\n",
      "Starting batch: 11\n",
      "Starting batch: 12\n",
      "Starting batch: 13\n",
      "Starting batch: 14\n",
      "Starting batch: 15\n",
      "Starting batch: 16\n",
      "Starting batch: 17\n",
      "Starting batch: 18\n",
      "Starting batch: 19\n",
      "Starting batch: 20\n",
      "Starting batch: 21\n",
      "Starting batch: 22\n",
      "Starting batch: 23\n",
      "Starting batch: 24\n",
      "Starting batch: 25\n",
      "Starting batch: 26\n",
      "Starting batch: 27\n",
      "Starting batch: 28\n",
      "Starting batch: 29\n",
      "Saving: Groups_v2/Group_3/group_3_batch_2.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_1.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_3.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_0.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_4.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_9.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_6.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_5.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_7.txt\n",
      "Saving: Groups_v2/Group_3/group_3_batch_8.txt\n"
     ]
    }
   ],
   "source": [
    "group_count = 3\n",
    "for original_dict in test:\n",
    "    \n",
    "    print(\"Starting Group:\", group_count)\n",
    "    group_size = original_dict['group_size']\n",
    "\n",
    "    # Remove the 'group_size' key from the new dictionary\n",
    "    del original_dict['group_size']\n",
    "    original_dict['place_of_residence'] = 'Montana, United States'\n",
    "\n",
    "    import concurrent.futures\n",
    "\n",
    "    batch_size = 5\n",
    "    max_workers = 5\n",
    "\n",
    "    # Calculate the number of full batches\n",
    "    full_batches = group_size // batch_size\n",
    "\n",
    "    # Calculate the number of remaining objects\n",
    "    remaining_objects = group_size % batch_size\n",
    "\n",
    "    personas = []\n",
    "\n",
    "    # Create a ThreadPoolExecutor with max_workers\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Create full batches of objects\n",
    "        for i in range(full_batches):\n",
    "            executor.submit(generate_and_save_persona, i, group_count)\n",
    "            print(\"Starting batch:\", str(i))\n",
    "        # Create remaining objects\n",
    "        if remaining_objects > 0:\n",
    "            executor.submit(generate_and_save_persona, full_batches, group_count)\n",
    "            print(\"Starting batch:\", str(full_batches))\n",
    "    \n",
    "    group_count += 1\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eb47c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_paragraph(persona, residence):\n",
    "    priorities = ', '.join(persona[\"Top Priorities\"])\n",
    "    try:\n",
    "        pain_points = ', '.join(persona[\"Pain points\"])\n",
    "    except:\n",
    "        pain_points = ', '.join(persona[\"Pain Points\"])\n",
    "    \n",
    "    return (f\"Your name is {persona['Name']}, you are a {persona['Age']} year old {persona['Ethnicity']} {persona['Gender']}. \"\n",
    "            f\"You live in {residence} and your annual income is ${persona['Income']}. \"\n",
    "            f\"Your marital status is {persona['Marital Status']}, and your highest level of education is {persona['Education Level']}. \"\n",
    "            f\"You work as a {persona['Occupation']}. You are described as '{persona['Description']}'. \"\n",
    "            f\"Your top priorities are {priorities}. You are facing some challenges, including {pain_points}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cecbde3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# parent_path = \"Groups/\"\n",
    "# # Define the directories to go through\n",
    "# directories = ['Groups/Group_1', 'Groups/Group_2', 'Groups/Group_3', 'Groups/Group_4']\n",
    "\n",
    "# # Define the string to find and the string to replace it with\n",
    "# find_string = '\"Nationality\": \"American\",'\n",
    "# find_string1 = '\"Nationality\": \"White\",'\n",
    "# replace_string = '\"Ethnicity\": \"White\",'\n",
    "\n",
    "# # For each directory\n",
    "# for directory in directories:\n",
    "#     # Use a wildcard (*) to find all .txt files in the directory\n",
    "#     for file_name in glob.glob(directory + '/*.txt'):\n",
    "#         print(file_name)\n",
    "#         # Open each file in read mode to get the data\n",
    "#         file_data = GPT.open_file(file_name)\n",
    "        \n",
    "#         # Replace the find_string with replace_string\n",
    "#         file_data = file_data.replace(find_string, replace_string)\n",
    "#         file_data = file_data.replace(find_string1, replace_string)\n",
    "        \n",
    "#         #print(new_data)\n",
    "        \n",
    "#         # Open the file in write mode to overwrite the original data with the new data\n",
    "#         GPT.save_file(file_name, file_data)\n",
    "\n",
    "# print(\"Replacement complete.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
